{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc54139d",
   "metadata": {},
   "source": [
    "## Predicting Marketing Campaign Response Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd01ca-2698-45a0-a3f5-1303359c2c7a",
   "metadata": {},
   "source": [
    "by Rabindranatah Duran Pons, Yasaman Eftekharypour, Valeria Siciliano, Rocco Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd460b6-90ca-490b-90f7-f2645ba5c12c",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7b2dc-80bb-43c7-b083-80feedef5f0c",
   "metadata": {},
   "source": [
    "In this project, we developed a machine-learning pipeline using logistic regression to predict whether a customer will subscribe to a marketing campaign. The workflow combined a preprocessing stage (StandardScaler and OneHotEncoder) with a logistic regression classifier, followed by training and evaluation using a train/test split.\n",
    "\n",
    "After applying class-weighting to address the dataset’s imbalance, the model achieved an accuracy of approximately 85% and a ROC-AUC of ~0.91, indicating strong overall discrimination between the subscribed (“yes”) and not-subscribed (“no”) classes. Importantly, class-weighting significantly improved the model’s ability to detect positive cases, giving the “yes” class a recall of 0.81. This shows that the weighted logistic regression approach is better suited for imbalanced marketing data, where correctly identifying potential subscribers is more valuable than simply maximizing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c686b0-a2e1-4e20-8efe-dda58b675909",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c8737-3608-4951-a344-c75bf953ab65",
   "metadata": {},
   "source": [
    "# todo: \n",
    "[provide some relevant background information on the topic so that someone unfamiliar with it will be prepared to understand the rest of your report]\n",
    "\n",
    "The main question explored in this project is:\n",
    "\n",
    "“Can we predict whether a bank customer will subscribe to a term deposit based on their demographic characteristics, financial information, and interactions with previous marketing campaigns?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c901880-0ebb-4ee4-8111-ca69c9478eb5",
   "metadata": {},
   "source": [
    "The dataset includes three main categories of features:\n",
    "\n",
    "1. Client demographics and personal information\n",
    "\n",
    "- age\n",
    "\n",
    "- job\n",
    "\n",
    "- marital\n",
    "\n",
    "- education\n",
    "\n",
    "- default (has credit in default)\n",
    "\n",
    "- housing (has housing loan)\n",
    "\n",
    "- loan (has personal loan)\n",
    "\n",
    "2. Current campaign interaction\n",
    "\n",
    "- contact — type of communication (cellular/telephone)\n",
    "\n",
    "- day_of_week — day of contact\n",
    "\n",
    "- month — month of campaign\n",
    "\n",
    "- duration — call duration in seconds\n",
    "\n",
    "- campaign — number of contacts during this campaign\n",
    "\n",
    "3. Past campaign and historical interaction\n",
    "\n",
    "- pdays — number of days since last contact\n",
    "\n",
    "- previous — number of previous contacts\n",
    "\n",
    "- poutcome — outcome of previous campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52aa217-a6a2-4432-aeec-66a5d3fbeb9b",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19695d45-0485-4929-89e4-af49690c249a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b7622-c9e6-4bee-8c20-ffcdb30d27ac",
   "metadata": {},
   "source": [
    "#### todo\n",
    "The data set used in this project is of ... created by ... at ... . \n",
    "Data can be found here [url...], specifically this file.\n",
    "Each row in the data set represents ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40608d83-e850-4501-9cf6-093f0749693a",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ee95b-b3c8-4309-87bc-5c8ea7b3ae0a",
   "metadata": {},
   "source": [
    "A logistic regression model was used to predict whether a marketing campaign will be successful or not. All original variables from the dataset were included in the analysis. Before fitting, numerical features were standardized with a StandardScaler, and categorical variables were converted to binary indicators via OneHotEncoder. The dataset was split into 80% training and 20% testing, and class imbalance was addressed by balancing class weights during model training. The model’s performance was evaluated using accuracy and ROC-AUC scores.\n",
    "\n",
    "The code used to perform this analysis and generate the accompanying report can be found here: \n",
    "#### todo ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbb6f4-ead7-4fb9-a09b-8ab5c380f03a",
   "metadata": {},
   "source": [
    "# Results & Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf201a9f-6d20-4b54-b389-88dfeddbfc87",
   "metadata": {},
   "source": [
    "The logistic regression model developed for this analysis provides meaningful insight into the factors associated with customer subscription, but it also highlights the intrinsic challenges of modeling imbalanced marketing data. Our pipeline combined appropriate preprocessing steps—StandardScaler for numerical features and One-Hot Encoding for categorical variables—with a LogisticRegression classifier to ensure proper handling of the heterogeneous dataset while respecting the Golden Rule and avoiding data leakage.\n",
    "\n",
    "The performance metrics indicate that the model performs reasonably well overall. The ROC-AUC score of approximately 0.91 suggests strong ability to distinguish between subscribers (“yes”) and non-subscribers (“no”). Although overall accuracy is around 0.85, accuracy alone is not an appropriate metric for this imbalanced context, because the majority class dominates the dataset.\n",
    "\n",
    "More importantly, the class-weighted logistic regression successfully shifts the model’s focus toward the minority class. The recall for the “yes” class reaches 0.81, a substantial improvement compared to what a non-weighted model would typically achieve on an imbalanced dataset. This indicates that the model is able to identify most customers who eventually subscribe—an outcome that aligns with the core business objective, where failing to detect potential subscribers is far more costly than incorrectly flagging non-subscribers. The precision for the “yes” class is lower (0.42), which is an expected trade-off: by increasing recall and giving more weight to positive cases, the classifier becomes more permissive and produces more false positives. However, in a marketing context—where the cost of contacting an uninterested customer is low compared to the value of identifying a true potential subscriber—this trade-off is acceptable and strategically desirable.\n",
    "\n",
    "The confusion matrix supports this interpretation. Out of 1,058 actual subscribers, the model correctly identifies 862 true positives while misclassifying 196 as non-subscribers. On the other hand, among the majority class, 6,786 non-subscribers are correctly classified, with 1,199 false positives. These numbers reflect a deliberate shift in the decision boundary due to class balancing: the model becomes more sensitive to the minority class at the expense of increasing false positives.\n",
    "\n",
    "Overall, the balanced logistic regression model is appropriate for this business problem. Its ability to capture a large portion of true subscribers, even with lower precision, aligns with the strategic goal of maximizing successful marketing outreach. By prioritizing recall in the positive class, the model supports proactive customer engagement and provides a meaningful foundation for future marketing campaigns.\n",
    "\n",
    "These results show that using a class-weighted logistic regression helps the model catch many more people who are likely to subscribe. This can be useful for marketing teams because it means they can focus their efforts on customers who are more likely to say “yes.” It also shows which factors—like the success of previous campaigns, the month of contact, or call duration—matter most, which can help improve how future campaigns are planned.\n",
    "\n",
    "These results also bring up a number of future questions. For example, it is unclear whether another type of model, such as a tree-based method, could perform even better than logistic regression on this imbalanced data. Another question is whether the same patterns would appear if we ran this analysis on a different marketing campaign or a different time period. Finally, it would be useful to understand which types of customers the model tends to misclassify most often, and whether adding more customer information could help the model make more reliable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73d9e8-9a0f-4381-9def-66be906d834a",
   "metadata": {},
   "source": [
    "The following code reads the data programatically and saves it to the data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86cfe8-218e-456f-b9f3-388199f8fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, \n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the data folder if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    " \n",
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222)\n",
    "\n",
    "# Convert the data into a pd dataframe\n",
    "X = bank_marketing.data.features \n",
    "y = bank_marketing.data.targets \n",
    "  \n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Save combined dataset to data folder\n",
    "df.to_csv(\"data/bank_marketing.csv\", index=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2b3af-ac63-43c3-b5f1-a7878b2fcf1d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55706ad1-1e4d-48d6-9061-43de6a413f4a",
   "metadata": {},
   "source": [
    "The following code performs some preliminary EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ee77f-2c09-4aef-868f-ef9115ea1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484dd910-6412-4c93-895d-7b7d5d0b5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5b077-3f8a-404e-b13c-c8a9a23a7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef73bd8-53d9-4238-97bb-afa765529407",
   "metadata": {},
   "source": [
    "The distribution of people who subscribed and didn't subscribe can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a9452-c5b6-49d4-a56a-ab4d962561dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify working with large datasets in Altair\n",
    "alt.data_transformers.enable('vegafusion')\n",
    "\n",
    "alt.Chart(df).mark_bar().encode(\n",
    "    y=alt.Y(\"y:N\", title=\"Subscribed\"),\n",
    "    x=alt.X(\"count()\", title=\"Count\"),\n",
    "    color=\"y:N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b95954-1a02-4bfc-a7ba-78d6d595e130",
   "metadata": {},
   "source": [
    "A comparison of the distribution of subscribed people among age can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc4c1d-fd2a-4c5a-8294-551ae0a207bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "alt.Chart(df)\n",
    ".transform_density(\n",
    "    density=\"age\",\n",
    "    groupby=[\"y\"],\n",
    "    as_=[\"age\", \"density\"]\n",
    ")\n",
    ".mark_area(opacity=0.4)\n",
    ".encode(\n",
    "    x=alt.X(\"age:Q\", title=\"Age\"),\n",
    "    y=alt.Y(\"density:Q\", title=\"Density\"),\n",
    "    color=alt.Color(\"y:N\", title=\"Subscribed\")\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8606ef6-eb82-4f3c-bd1e-a2602cf34f34",
   "metadata": {},
   "source": [
    "The following cleans the data, fits the model and makes predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b004299-35ff-4398-8623-3447be4cd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['education'].unique())\n",
    "print(df['marital'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c43291-d4b8-4d2d-bbb5-3c8240546ca7",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481e607-1c75-4892-9b17-607f505212df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df[df['education'] != 'unknown']\n",
    "df = df[df['job'] != 'unknown']\n",
    "df = df[df['marital'] != 'unknown']\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f95fc-79ef-47ab-9457-862f8f0cbf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable: y = \"yes\" or \"no\"\n",
    "df[\"y\"] = df[\"y\"].map({\"yes\": 1, \"no\": 0})\n",
    "df[\"housing\"] = df[\"housing\"].map({\"yes\": 1, \"no\": 0})\n",
    "df[\"loan\"] = df[\"loan\"].map({\"yes\": 1, \"no\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58831766-8ec9-4ec1-8ac4-6049937413b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split features and target\n",
    "\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56c8c7-7f93-41d8-a436-7e490d8440a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Preprocessing pipeline\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa5305-5953-4ecb-9967-8057c80c5711",
   "metadata": {},
   "source": [
    "# Fitting the model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb51bd1-955d-491b-92b6-a2aade1d37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Build model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, class_weight =\"balanced\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3ad92-5e7b-42f5-98b1-c44bd50b06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc644e6a-7b23-4a49-8976-3f7a80c50138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Train model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44b269-f91d-4fc2-a922-5b27700c0400",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 9. Predictions and evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap=\"Blues\", \n",
    "            xticklabels=[\"no\", \"yes\"],\n",
    "            yticklabels=[\"no\", \"yes\"]\n",
    "            )\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353b525-3a3d-42e1-a6a0-61a1bebc7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Feature Importance (for logistic regression)\n",
    "# This is a bit tricky with pipelines — we extract processed feature names\n",
    "ohe = model.named_steps[\"preprocessor\"].named_transformers_[\"cat\"][\"onehot\"]\n",
    "cat_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "feature_names = np.concatenate([numerical_cols, cat_feature_names])\n",
    "\n",
    "# Get coefficients\n",
    "coeffs = model.named_steps[\"classifier\"].coef_[0]\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": coeffs\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(feat_imp.head(10))\n",
    "feat_imp.head(20).plot(kind=\"bar\", x=\"feature\", y=\"importance\", figsize=(10,5))\n",
    "plt.title(\"Feature Importance (Logistic Regression Coefficients)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1da2c1-93ff-4239-8ade-ff6e3725e77d",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa2f5b4",
   "metadata": {},
   "source": [
    "A data modeling approach for classification problems: application to bank telemarketing prediction\n",
    "Stéphane Cédric KOUMETIO TEKOUABOU, Walid Cherif, H. Silkan\n",
    "Published in International Conferences on… 27 March 2019\n",
    "Computer Science, Business\n",
    "https://www.semanticscholar.org/paper/A-data-modeling-approach-for-classification-to-bank-TEKOUABOU-Cherif/241d6ca92c4bc65ac3ee903e4732f70bff5c5e9f\n",
    "\n",
    "\n",
    "Predicting the Accuracy for Telemarketing Process in Banks Using Data Mining\n",
    "F. Alsolami, Farrukh Saleem, A. Al-malaise, AL-Ghamdi, Published 2020\n",
    "Business, Computer Science\n",
    "https://www.semanticscholar.org/paper/Predicting-the-Accuracy-for-Telemarketing-Process-Alsolami-Saleem/6391b7edcdd3c443bb57624b153bf9a8cca027db\n",
    "\n",
    "\n",
    "Using Logistic Regression Model to Predict the Success of Bank Telemarketing\n",
    "Y. Jiang, Published 21 June 2018\n",
    "Business, Computer Science, Journal of data science\n",
    "https://www.semanticscholar.org/paper/Using-Logistic-Regression-Model-to-Predict-the-of-Jiang/11ea58c843d0e745716d624b03067235dc285c30\n",
    "\n",
    "\n",
    "Prediction of Term Deposit in Bank: Using Logistic Model Enjing Jiang, Zihao Wang, Jiaying Zhao, Published in BCP Business &amp; Management 14 December 2022\n",
    "Business, Computer Science\n",
    "https://www.semanticscholar.org/paper/Prediction-of-Term-Deposit-in-Bank%3A-Using-Logistic-Jiang-Wang/e36cafceaad636e9b2b558166c16be31a913ad0d\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env 522)",
   "language": "python",
   "name": "522"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
